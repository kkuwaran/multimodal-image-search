{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from clip_embedder import CLIPEmbedder\n",
    "from tiny_imagenet_db import Image, load_tiny_imagenet, search_images\n",
    "from app import generate_app\n",
    "\n",
    "# Enable inline plotting for Jupyter Notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and dataset configurations\n",
    "MODEL_NAME = \"openai/clip-vit-base-patch32\"  # Pre-trained CLIP model\n",
    "DATA_SPLIT = \"valid\"                         # Dataset split to use (train/valid)\n",
    "TABLE_NAME = \"image_search\"                  # Table name for LanceDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset and Define Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Tiny-ImageNet dataset for the specified split\n",
    "dataset = load_tiny_imagenet(DATA_SPLIT, verbose=True)\n",
    "\n",
    "# Initialize the CLIP pipeline for embedding generation\n",
    "pipeline = CLIPEmbedder(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed Images and Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_embed_image(batch: dict) -> dict:\n",
    "    \"\"\"Generate image embeddings for a batch of images.\"\"\"\n",
    "    embeddings = pipeline.embed_image(batch[\"image\"])\n",
    "    return {\"vector\": embeddings}\n",
    "\n",
    "\n",
    "# Apply the embedding function to the dataset\n",
    "processed_dataset = dataset.map(map_embed_image, batched=True, batch_size=128)\n",
    "\n",
    "# Display the processed dataset information\n",
    "print(processed_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LanceDB Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LanceDB table from the processed dataset\n",
    "table = Image.create_table(TABLE_NAME, processed_dataset)\n",
    "\n",
    "# Display the first few rows of the table\n",
    "display(table.head().to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search and Visualize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a text query for image search\n",
    "text_query: str = \"fish\"\n",
    "\n",
    "# Test the search_images function\n",
    "retrieved_images = search_images(pipeline, table, text_query, verbose=True)\n",
    "\n",
    "# Visualize the retrieved images in a 3x3 grid\n",
    "fig, axes = plt.subplots(3, 3, figsize=(6, 6))  # Adjust figsize for better display\n",
    "for ax, img in zip(axes.ravel(), retrieved_images):\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Gradio App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = generate_app(pipeline, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
